<h1 align="center">Telecom Customer Churn</h1>
<p align="center">
  <img src="https://koptel.co.id/assets/img/static/logo_koptel.png"></img>
</p>

## Project's Background
PT. Telco is a company that has products and services such as telephone, internet, online security, online backup, device protection, technical support, and TV and movie streaming. In facing service competition in the market, companies need to know the behavior of their customers.

Customer churn is defined as when a customer stops service from the company. In this highly competitive sector, the telecom industry has an annual churn rate of 15-25%. Customer layoffs in the telecommunications industry pose one of the most significant risks to lost revenue. Since it costs up to 25 times more to acquire new customers than it costs to retain them, cultivating customer loyalty is the key.

1. What is the behavior of customers who end up being churn?
2. Does the monthly service contract affect the occurrence of churn?
3. How many customers end up being churn based on the charges?
4. What is the percentage of churn when viewed by tenure?
5. Classify to predict whether a customer will churn or not! and choose the best model
---
## Objectives
Creating a Classification model to predict Customers Churn using the Artificial Neural Network Algorithm

*This project* is done in *notebook* format with/or with *deployment model* (optional) with the following *mandatory criteria*:

1. The Deep Learning framework used is *Tensorflow*.

2. There is use of a visualization library, such as *matplotlib*, *seaborn*, or others.

3. The contents of *notebook* must follow the *outline* below:
    1. Introductions
       > The introductory chapter must be filled with identity, a big picture of the dataset used, and the *objective* you want to achieve.
   
    2. Import Libraries
       > The first *cell* in *notebook* **must contain and contain only** all *libraries* used in *project*.
   
    3. Data Loading
       > This section contains the data preparation process prior to further data exploration. The Data Loading process can be in the form of giving a new name to each column, checking the size of the dataset, etc.
   
    4. Exploratory Data Analysis (EDA)
       > This section contains data exploration in the dataset above by using queries, groupings, simple visualizations, and so on.

    5. Data Preprocessing
       > This section contains the process of preparing data for the model training process, such as dividing data into train-dev-test, data transformation (normalization, encoding, etc.), and other processes needed.
   
    6. Model Definition
       > This section contains cells to define the model. Explain the reasons for using an algorithm/model, the hyperparameters used, the types of metrics used, and other things related to the model.

    7. Model Training
       > Cells in this section only contain code to train the model and the resulting output. Do the training process several times with different hyperparameters to see the results obtained. Analyze and narrate these results in the Model Evaluation section.
   
    8. Model Evaluation
       > In this section, a model evaluation is carried out which must show how the model performs based on the selected metrics. This should be proven by visualizing performance trends and/or model error rates. **Perform analysis related to the results on the model and write down the results of the analysis**.

    9. Model Saving
       > By looking at the model evaluation results, choose the best model to save. This best model will be reused in deploying on Heroku.
   
    10. Model Inference
        > Models that have been trained will be tried on data that is not included in the train-set or test-set. This data must be in the original format, not data that has been scaled.
   
    11. Conclusion
        > In this last section, **must contain** conclusions that reflect the results obtained with the *objective* that has been written in the introduction section.
